\section{Introduction}

The proposed techniques in this paper are motivated in large part by progress in automated testing.  Recent advances, some implemented in powerful tools \cite{csmith,jsfunfuzz,ISSTA12,LangFuzz,ZhendongPLDI,ZhendongOOPSLA}, have made it easier to find subtle faults in modern optimizing compilers.  Unfortunately, the blessing of many failing test cases can become a curse for a developer.  Simply discovering which test cases in a large set of failures represent distinct faults (or already known faults) is a very difficult problem \cite{PLDI13,Podgurski04}.  For simple crashes and assertion violations, bucketing failures is sometimes easy.  When a failure is detected by differential testing \cite{Differential}, where two compilers or optimization levels disagree, the problem is so hard that it may turn potential users away from automated test generation \cite{PLDI13}.  Such \emph{wrong code} bugs do not produce a crash, only two compiled programs with different, incorrect (in at least one case) behavior.  Even once a fault is identified, fixing the problem can be very difficult.  Due to complexity of intermediate representation, interaction of optimizations, subtle language semantics, and other issues, debugging compiler faults may often be harder than debugging faults in other kinds of software (this is probably not limited to compilers; debugging systems software in general is hard \cite{mickens}).
This paper proposes the use of mutants \cite{mutant} to assist debugging based on large sets of automatically generated test cases.  The underlying idea is that if two failures can be repaired, by applying the same program mutant, \emph{even if the repair only avoids the failure and does not truly fix it}, the two failures are likely due to the same fault. Repairs can also provide  information for understanding and debugging discovered faults. The approach suggests a plausible metric for comparing any two program executions, not just failing test cases.  Comparing executions has been a prominent concept in dynamic analysis throughout much of the last two decades \cite{NearNeighbor,Sumner2011} (e.g., Ball's early discussion of profile similarity \cite{BallConcept}).

\subsection{Fuzzer Taming and Debugging Assistance}

Automated test generators tend to produce many failures, which correspond to far fewer faults.  The distribution of faults in a set of failures tends to follow a strong power-law curve, where a few faults account for most failures, and many or even most faults have only 1 or 2 associated failures (even in a set of 1,000 or more test cases) \cite{PLDI13,OneTest}.  Looking at all the failures to find  distinct faults is impractical.  It is also impractical to apply the iterative approach:  first, fix one test's fault; then re-run all tests, until all tests pass.  There may be some (possibly known) faults that are very difficult to fix. As of 5/8/2017, clang had 107 unresolved, assigned bugs, some dating to 2008 \cite{clangbugs}.  Knowing if a randomly generated test case is an instance of a known failure can be difficult, and fixing long-standing problems is unlikely.    Applying a novel fuzzing technique \cite{csmith,ISSTA12,ZhendongPLDI} may dump dozens of new faults on a project at once, and high priority faults may be hidden by stubborn low-priority faults.

Chen et al. defined the \emph{fuzzer taming problem}: ``Given a potentially large collection of test cases, each of which triggers a bug, rank them in such a way that test cases triggering distinct bugs are early in the list.'' \cite{PLDI13}.  Their proposed solution was to use the Furthest-Point-First \cite{Gonzalez} (FPF) algorithm.  An FPF ranking of test cases requires a distance metric $d$ on test cases, and ranks test cases so that dissimilar tests appear earlier.  The hypothesis of Chen et al. was that dissimilar tests, by a well-chosen metric, will also fail due to different faults.
FPF is a greedy algorithm that proceeds by repeatedly adding the item with the maximum minimum distance to all previously ranked items. Given an initial seed item $r_0$, a set
$S$ of items to rank, and a distance metric $d$, FPF computes $r_i$ as $s \in S: \forall s' \in S: min_{ j < i}(d(s,r_j)) \geq min_{j < i}(d(s',r_j))$.

Fuzzer taming results using FPF were promising, but limited.  Rather than proposing a universal metric for use in fuzzer taming, Chen et al. offered many possible metrics (based on ideas in the literature, such as edit distances \cite{lev} or coverage spectra \cite{RepsSpectra} methods), none of which performed notably well across all three of their benchmark data sets, and some of which were not even applicable to all data sets.  For the two most difficult benchmarks, none of the metrics performed extremely well. FPF-based approaches remain in need of a universal but effective metric, particularly for the critical first 50 test cases examined \cite{PLDI13}.

One reason fuzzer taming is needed is that debugging compiler faults is, as noted, difficult.  If developers were able to fix faults quickly once they were identified, it would not be as important to have very good fault identification.  Many duplicate failures could be removed by fixing the underlying faults.  Ideally, a technique able to provide effective fuzzer taming should be able to translate its underlying rationale into some form of automated debugging assistance.   A variety of automated debugging methods \cite{NearNeighbor,GroceError} have been based on distance, so there is reason to expect that a high-quality metric might also contribute to fault localization.

\subsection{Comparison by Response to Mutation}

The methods we propose are based on an idea with numerous possible applications: \emph{if two test cases that fail can be made to succeed by the same small modification to the original program $P$, this provides evidence that they fail due to the same fault}.  The idea is hardly controversial:  most developers determine if they have fixed all faults in a set of failing test cases by re-running the tests after they fix at least one fault.  As a method for fuzzer taming or debugging assistance, however, this is useless.  Fortunately, developer-provided patches are not the only source of changes to a program.  Mutation analysis \cite{demillo1978hints,budd1980theoretical} applies large numbers of small syntactic changes to a program, usually to evaluate a test suite \cite{mutant,justmutants}.  Some recent work has also considered these changes as a source of fixes or localizations for program faults \cite{achour,multilingual,MUSE,DebroyMutant}.  Published empirical data \cite{GopinathMutants}, as well as our data, suggests that very few compiler faults are due to the kind of simple syntactic changes found in mutants.  However, what should matter is that failures, which correspond to faults, can be made to succeed.  When a test case $t$ fails for program $P$ but succeeds for mutant $m$ of $P$ we say that $m$ \emph{repairs} $t$ (in practice, we will usually restrict this to unkilled mutants $m$).  In most cases this does not mean that $m$ is the inverse of a fault, but that $m$ somehow avoids the consequence of a fault.  It is not important that repairs actually fix anything, if all we seek is a way to decide whether failures are due to the same fault.

This idea is in fact a consequence of a more general (and difficult to investigate) hypothesis.  What is interesting about a program execution?  For many purposes, the only interesting properties of an execution are those that in some way relate to the correctness properties of the program, assuming we have a good set of correctness properties.  These may include assertions, differential testing \cite{Differential,ICSEDiff}, timing constraints, temporal logic formulas, or any other checkable properties.  What, then, makes two executions similar?  Our proposal is that \emph{two executions of $P$ are similar to the degree that changes to $P$ produce the same changes in correctness of the executions.}

This leads to the general idea of comparing any two executions by their response to mutants, since a mutant can cause a passing or failing test to violate more/different properties.   
This generalization to any two executions may at first glance suggest that our approach subsumes past notions of similarity, such as spectra of code coverage, since if two executions do not cover a statement, they both cannot alter correctness if that statement is altered.  The metrics are in fact simply incomparable:  for example, differences in coverage that never have an effect on correctness cannot contribute to similarity in our approach; with weak correctness properties most executions are very similar.  This is similar to the idea of \emph{checked coverage}:  code that cannot impact correctness is not interesting \cite{CheckCov}.  
However, for practical purposes the most interesting implication of our proposal is that if two failing test cases can be made to differ as to whether they fail by applying a program mutant, this provides evidence that they fail due to different faults.


\subsection{The Onion-Ring and Causality}

This not a claim that being repaired by the same mutant perfectly predicts fault equivalence.  To understand why that seems highly unlikely, consider why a mutant of a compiler might cause a test case to stop failing.  Many, likely most, compiler faults are due to incorrect optimizations.  Turning an optimization off can cause a program to compile correctly.  Optimizations are generally guarded by conditional switches --- in some cases, so that the optimization can be turned off by a user, in other cases when a property of the code in question prevents the optimization.  If two failures become successes due to turning off an optimization, it is presumably \emph{some} level of evidence they are the same fault, compared to the baseline probability.  Intuitively, the evidence provided seems much stronger than the fact that, e.g., the two test cases execute a shared line of code \cite{RepsSpectra}.  However, optimization guards range from guarding very specific fragments of code to guarding entire modules with many functions and related sub-optimizations.  If a mutant prevents a very specific optimization (consisting of a few lines of code) from executing, and repairs two tests, that is powerful evidence they are related.  If a mutant turns off a large number of optimizations, it is weak evidence.  Must we then characterize mutant granularity?  No.

\begin{figure}
\centering
\includegraphics[width=0.4\columnwidth]{onionring}
\caption{\scriptsize{Onion-ring shows all repairs for the center-most test case, and all other test cases repaired by same mutants.  Rings represent repairing mutants, and diamonds test cases.  Diamond pattern symbolizes fault.  For innermost ring, all failures are due to the same fault.  As rings expand, the set of faults grows (as does distance).}}
\vspace{-0.1in}
\label{fig:onion}
\end{figure}

Consider the structure of mutants repairing a failure due to some optimization.  If many mutants repair this failure, by turning off the optimization or a whole family of optimizations, some will likely repair failures due to different faults.  Repairs naturally produce an \emph{onion-ring} structure (Figure \ref{fig:onion}), where a failure is repaired by (1) some mutants that are very specific to its fault (the inner rings) and repair few failures, as well as other mutants (2) that repair more and more faults, up to a hypothetical mutant (3) that turns off all optimization in the compiler (e.g., by effectively adding {\tt -O0}), the outer ring of the onion.  This does not introduce confusion, because the more repairs two tests have in common, the more likely they are to be due to the same fault, and the more they disagree on, the less likely they are to be due to the same fault.  While especially intuitive as a consequence of disabling compiler optimizations, it seems likely this structure appears for repairs in many programs.  Disabling an optimization is a code change that (usually) does not cause any test case that only concerns semantics, not speed, to fail, but can avoid some failures.  For some oracles, many changes may fall into this classification:  for example, if the only oracle is to detect crashes, a fault can be avoided by aborting the program early.  Turning off a data-structure invariant checker is another possible false repair that might cover many different faults.  In all these cases, assuming more interesting and specific ways to repair faults exist, a distance metric can still work.

The idea of measuring the distance between failures (or other test cases) by their response to mutants is appealing.  The most important aspect of most applications of distances between executions is some aspect of causality \cite{LewisCause,ZellerBook}.  Since at least the work of Hume \cite{Hume1}, causality has been understood as answering some question of the form ``what would have made a difference in this effect?''  A program mutant is a very direct way to answer this question.  The problem with determining causes of events in computer programs is that, as in most problems of causality, too many things can make a difference, most of which are not interesting.  Program mutants are much more likely to be interesting causes for events in a program than changes to test cases, at least for fault identification and debugging purposes, because the practical use of knowing a cause is to change the cause and avoid or produce an effect.  Debugging by changing test cases is not useful; debugging by altering the program is precisely how we seek to use the causes we discover.  Using mutants as causes in order to measure similarity ``inverts'' the ideas of Lewis \cite{LewisCause,LewisCount}, where similarity determines causality.  One pleasant side-effect is that execution representation \cite{NearNeighbor,RepsSpectra} is not a difficulty for this kind of metric, since an execution is always represented as a set of correctness evaluations.

This paper investigates the utility of using distance metrics based on the causal approach suggested above.  We show that such a metric can improve, in a statistically significant way, the ability to distinguish tests based on which faults they trigger.  Furthermore, fault localization based on the same metrics can successfully pinpoint the location of some compiler faults sufficiently to be likely to substantially aid debugging, and, when applicable, performs very well for some faults studied in recent papers on mutant-based fault localization \cite{multilingual,Papadakis}.

\subsection{Contributions}

This paper extends our 2018 ISSRE paper \cite{ISSRE18Mutants} introducing our approach. That paper introduced a novel way of measuring distance between program executions, but more importantly provided some practical proposals for using such a metric in compiler fuzzer taming and fault localization.  Our experimental results show that, for two realistic complex compilers, Mozilla's SpiderMonkey 1.6 JIT for JavaScript and GCC 4.3.0, using mutant response metrics improves FPF-based fuzzer taming over best previous results \cite{PLDI13}, in multiple ways.  Our fault localization approach also compares favorably to state-of-the-art fault localization techniques \cite{MUSE,multilingual,Metallaxis} for non-compiler programs, albeit with a more limited applicability (but also a lower cost).  We extend the earlier paper by:

\begin{itemize}
\item generally expanding discussion of our approach, including the conceptual basis for using mutants to measure similarity of executions, and related work,
\item providing an extended example (in Section \ref{sec:example}) to help readers better understand the metric, FPF-based fuzzer taming, and our fault localization approach,
\item introducing and evaluating another compiler fault localization approach (in Section \ref{sec:covloc}), based on code coverage changes,
\item and including a much more in-depth examination of the computational costs of our approach and various ways of reducing that cost, including experimental evaluations (in Section \ref{sec:highcost}).
\end{itemize}